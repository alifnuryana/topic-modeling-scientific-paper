{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Preprocessing",
   "id": "e314ce564918e029"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T14:01:40.070055Z",
     "start_time": "2024-08-03T14:01:39.831659Z"
    }
   },
   "cell_type": "code",
   "source": "from sklearn.preprocessing import FunctionTransformer",
   "id": "3e1953edf446bed7",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T14:01:40.073287Z",
     "start_time": "2024-08-03T14:01:40.071069Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def lowercase_transformer(X):\n",
    "    return X.str.lower()\n",
    "\n",
    "\n",
    "lowercase_transformer = FunctionTransformer(lowercase_transformer)"
   ],
   "id": "facf7f507a23fbc0",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T14:01:40.098740Z",
     "start_time": "2024-08-03T14:01:40.074236Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def remove_numbers_transformer(X):\n",
    "    X = X.astype(str)\n",
    "    return X.str.replace(r'\\d+', '', regex=True)\n",
    "\n",
    "\n",
    "remove_numbers_transformer = FunctionTransformer(remove_numbers_transformer)"
   ],
   "id": "959431b435fb2c09",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T14:01:40.101972Z",
     "start_time": "2024-08-03T14:01:40.099775Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def remove_punctuation_transformer(X):\n",
    "    return X.str.replace(r'[^\\w\\s]', '', regex=True)\n",
    "\n",
    "\n",
    "remove_punctuation_transformer = FunctionTransformer(remove_punctuation_transformer)"
   ],
   "id": "7572484cef09395c",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T14:01:40.105637Z",
     "start_time": "2024-08-03T14:01:40.103529Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def remove_whitespace_transformer(X):\n",
    "    return X.str.strip()\n",
    "\n",
    "\n",
    "remove_whitespace_transformer = FunctionTransformer(remove_whitespace_transformer)"
   ],
   "id": "36cb36f63dc9538",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T14:01:40.312525Z",
     "start_time": "2024-08-03T14:01:40.106492Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import nltk\n",
    "import os\n",
    "\n",
    "nltk_data_dir = os.path.expanduser('~/Tools/nltk_data')\n",
    "if not os.path.exists(nltk_data_dir):\n",
    "    os.makedirs(nltk_data_dir)\n",
    "\n",
    "nltk.data.path.append(nltk_data_dir)\n",
    "# nltk.download('stopwords', download_dir=nltk_data_dir)\n",
    "\n",
    "\n",
    "def load_custom_stopwords(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        stopwords = set(line.strip().lower() for line in file)\n",
    "    return stopwords\n",
    "\n",
    "\n",
    "nltk_stopwords = set(nltk.corpus.stopwords.words('indonesian'))\n",
    "custom_stopwords = load_custom_stopwords('../utils/stopwords-id.txt')\n",
    "all_stopwords = nltk_stopwords.union(custom_stopwords)\n",
    "\n",
    "\n",
    "def remove_stopwords(X):\n",
    "    return X.apply(lambda x: ' '.join([word for word in x.split() if word.lower() not in all_stopwords]))\n",
    "\n",
    "\n",
    "remove_stopwords_transformer = FunctionTransformer(remove_stopwords)"
   ],
   "id": "370fcf79cfb65630",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T14:01:40.315653Z",
     "start_time": "2024-08-03T14:01:40.313315Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def remove_short_words_transformer(min_length):\n",
    "    def remove_short_words(X):\n",
    "        return X.apply(lambda x: ' '.join([word for word in x.split() if len(word) > min_length]))\n",
    "\n",
    "    return remove_short_words\n",
    "\n",
    "\n",
    "remove_short_words_transformer = FunctionTransformer(\n",
    "    remove_short_words_transformer(3)\n",
    ")"
   ],
   "id": "b52b0792916db9b1",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T14:01:40.693818Z",
     "start_time": "2024-08-03T14:01:40.316562Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from nlp_id.lemmatizer import Lemmatizer\n",
    "\n",
    "lemmatizer = Lemmatizer()\n",
    "\n",
    "\n",
    "def lemmatization_transformer(X):\n",
    "    return X.apply(lambda x: ' '.join([lemmatizer.lemmatize(word) for word in x.split()]))\n",
    "\n",
    "\n",
    "lemmatization_transformer = FunctionTransformer(lemmatization_transformer)"
   ],
   "id": "85e9e2cae39e0c29",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T14:01:40.697366Z",
     "start_time": "2024-08-03T14:01:40.694687Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "preprocessing_pipeline = Pipeline([\n",
    "    ('lowercase', lowercase_transformer),\n",
    "    ('remove_punctuation', remove_punctuation_transformer),\n",
    "    ('remove_numbers', remove_numbers_transformer),\n",
    "    ('remove_whitespace', remove_whitespace_transformer),\n",
    "    ('remove_short_words', remove_short_words_transformer),\n",
    "    ('lemmatization', lemmatization_transformer),\n",
    "    ('stopwords_remover', remove_stopwords_transformer),\n",
    "])"
   ],
   "id": "dd6e2e1ddef46aaa",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T14:01:46.419436Z",
     "start_time": "2024-08-03T14:01:40.698217Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "study_programs = pd.read_csv('../data/raw/02082024.csv')['study_program'].unique()\n",
    "\n",
    "for study_program in tqdm(study_programs, desc=\"Processing files\"):\n",
    "    file_name = f\"../data/raw/{study_program.lower().replace(' ', '-')}-raw.csv\"\n",
    "\n",
    "    if os.path.exists(file_name):\n",
    "        df = pd.read_csv(file_name)\n",
    "\n",
    "        abstracts = df['abstract']\n",
    "        abstracts_processed = preprocessing_pipeline.fit_transform(abstracts)\n",
    "\n",
    "        output_file_name = f\"../data/preprocessed/{study_program.lower().replace(' ', '-')}-preprocessed.csv\"\n",
    "        abstracts_processed.to_csv(output_file_name)\n",
    "\n",
    "        tqdm.desc = f\"Processed {study_program}\"\n",
    "    else:\n",
    "        tqdm.write(f\"File {file_name} does not exist.\")"
   ],
   "id": "9b5a157fe1aaeff1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████| 11/11 [00:05<00:00,  2.05it/s]\n"
     ]
    }
   ],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
